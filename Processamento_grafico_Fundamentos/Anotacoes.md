-> anota√ß√µes da cadeira
-> **Reposit√≥rio de exemplos:** https://github.com/fellowsheep/PG2024-2
Ser√° extremamente importante e de boa venturan√ßa usar esse reposit√≥rio

DATA: 13/Aug/24
-> Procure baixar o OpenGL 3.3 -> Blender

- A disciplina vai ser baseada em OpenGL para fins de aprendizado e resolu√ß√£o de pequenos problemas
  - mais para frente o correto seria usar o Vulkan
- OpenCV √© um tanto mais amig√°vel que o OpenGL
- Ambas as bibliotecas s√£o baseadas em C/C++
  - A disciplina provavelmente vai levar √† usar C/C++
- Ponteiros normalmente s√£o trabalhados com algumas "ajudas"
  - Use C++ preferencialmente -> mais suporte da linguagem

# Refer√™ncias pr√°ticas (link)
‚Ä¢ https://learnopengl.com/
‚Ä¢ http://www.opengl-tutorial.org/
‚Ä¢ http://docs.gl/
‚Ä¢ https://github.com/fellowsheep/PG2024-2 -> esse √© um reposit√≥rio √≥timo com alguns tutoriais pra settar o ambiente de desenvolvimento

# Processamento gr√°fico
**"√â o processamento de informa√ß√µes visuais, tanto para gera√ß√£o de imagens, quanto obten√ß√£o de dados.**
Processamento gr√°fico (ou PG) est√° presente em diversas √°reas da computa√ß√£o moderna (e baseia a maior parte dos games e entretenimento modernos).
√â bastante poss√≠vel identificar duas grandes √°reas:
- Processamento de imagens - tratamento e vis√£o computacional
- Computa√ß√£o gr√°fica - s√≠ntese e *pipeline* (processo/cadeia de *renderiza√ß√£o* tanto 2D quanto 3D).
Tenha em mente a diferen√ßa fundamental entre processamento e tratamento
- *Processamento* - extra√ß√£o de dados de uma imagem
  - passa por um processamento computacional de an√°lise dos pontos da imagem a fim de (tentar) compor dados √† partir dela - detec√ß√£o facial, placas de ve√≠culos, etc.
  - esse processamento √© chamado de vis√£o computacional a partir do momento que as informa√ß√µes da imagem s√£o "enxergadas" pelo computador
  - identifica√ß√£o de marca√ß√µes tamb√©m permitem tecnologias de realidade aumentada (AR) - sim, os filtros de instagram s√£o AR
- *Tratamento* - altera√ß√£o e composi√ß√£o da imagem, sem retirar dados (Photoshop)

- Processamento pra gerar ou extrair info de imagens (grande √°rea)
- usado pra placas de carro por exemplo
- as √°reas de processamento gr√°fico mudam conforme a express√£o
  - imagens est√°ticas tendem a ser mais simples e f√°ceis de compreender -> filtro e edi√ß√£o (paint) facilitam a vida
  - modelos ainda n√£o viraram imagens
    - guardam informa√ß√µes de ilumina√ß√£o, cor, geometria
    - normalmente as informa√ß√µes s√£o somente num√©ricas
    - s√≥ vira pixel depois da renderiza√ß√£o (sintetiza√ß√£o) -> computa√ß√£o gr√°fica
  - em vis√£o computacional o input √© a imagem e o output s√£o as informa√ß√µes para tratamento
    - aqui entra em parte na realidade aumentada
    - fica mais pr√≥ximo de design de intera√ß√£o

# Computa√ß√£o gr√°fica
O processo de *computa√ß√£o gr√°fica* *(CG) √© basicamente sintetizar todos os dados para gera√ß√£o de uma imagem. Se for√ßar um pouco a barra, d√° para dizer que √© o processo inverso do processamento gr√°fico.
Uma modelagem em CG tem algumas *primitivas* b√°sicas. Sempre ser√° uma coordenanda de 3 pontos. Tenha em mente que CG utiliza o espa√ßo 3D para modelagem das figuras e, para tanto, tem 3 eixos (x, y, z), sempre nessa ordem. Seguindo nessa ideia, podemos montar pol√≠gonos com esses pontos de coordenada e montar malhas (*Mesh*) a fim de gerar as figuras.
Um fato interessante √© que preferencialmente se gera figuras com tri√¢ngulos, j√° que possui menos pontos para ger√°-lo (ferramentas inclusive mostram op√ß√µes de "trianguloficar" os modelos 3D).
- *Frame buffer*: √â uma por√ß√£o de mem√≥ria usada para criar o
pixel map que ser√° enviado para o monitor.
- *Double buffering*: t√©cnica que utiliza um buffer auxiliar
para criar imagem enquanto um buffer √© desenhado
(altern√¢ncia). Usado para evitar o flicker (tremer a
imagem)
*Game loop* √© um conceito de pipeline que sempre *atualiza*, *renderiza* e *sincroniza* dados e processamento de imagem para lan√ßar ao I/O (normalmente o monitor) - mais sobre isso na sequ√™ncia.

## Renderiza√ß√£o
- Essa t√©cnica utiliza c√°lculos (normalmente vetoriais) para transposi√ß√£o do que seria um ambiente 3D (se for uma renderiza√ß√£o 3D) para um plano 2D (tela do monitor - matriz - e o processamenmto de uma GPU). Todo o c√°lculo de luz e como ela interage com o ambiente, al√©m da tradu√ß√£o para a vizualiza√ß√£o em matriz, √© feita nessa fase.


- CG
- representa√ß√£o de objetos e modelos usam v√©rtices/pontos -> coordenadas no espa√ßo
  - normalmente associados no modelo 3D, mas o 2D tbm usa obviamente
- a jun√ß√£o dessas coordenadas formam os pol√≠gonos
  - normalmente a primitiva √© na forma de um tri√¢ngulo
  - rotacionamento e planos s√£o formados com esses elementos
  - √°lgebra linear √© usada conceitualmente
- a origem do sistema cartesiano √© 0,0,0 -> canto do sistema
- √© interessante atrelar as unidades dos operadores 3D (como o Blender) pra unidades reais (e.g. metros) para coer√™ncia
- em geral para os c√°lculos, arestas n√£o s√£o t√£o utilizadas
  - em processamento gr√°fico em algumas situa√ß√µes as arestas podem ser √∫teis
- no contexto de CG, pol√≠gono e face √© a mesma coisa
- o fato de tri√¢ngulos serem o pol√≠gono com menor n√∫mero de v√©rtices, ele √© bastante usado para implementa√ß√µes efetivas (mais est√°veis e baratas computacionalmente)
  - algoritmos mais efetivos utilizam malhas triangularizadas de pol√≠gonos
- t√©cnica de subdivis√£o de superf√≠cies
  - aumenta a quantidade de pol√≠gonos e procura quadruplicar a quantidade de pol√≠gonos
  - fica cada vez mais *smooth*
  - s√≥ precisa cuidar pra n√£o explodir a quantidade de pol√≠gonos no modelo
  - os pontos n√£o podem ser colineares
### game loop
- desenho do processo gr√°fico
- processamento mais simples das entradas dos usu√°rios - detec√ß√£o de eventos
- render √© a fase onde o processamento realmente acontece - faz parte do gameloop para computar as altera√ß√µes realizadas no programa
### Renderiza√ß√£o
- render
- ainda √© informa√ß√£o visual sem a transposi√ß√£o pra pixel
- imagens s√£o dados bidimensionais
- wireframe view - aramado - estrutura b√°sica poligonal
- solid view - geometria sobre os pol√≠gonos com shadding (shaders - sombreamento)
- rendering - ilumina√ß√£o e p√≥s-processamento - mais pr√≥ximo da imagem final - ainda aparece debugs
- render usa vetores dos objetos para a tela e calcular o direcionamento dos raios de luz
  - inclusive, alguns tipos de material precisam guardar informa√ß√µes de outros objetos - a maioria dos c√°lculos s√£o feitos na hora - dependendo da complexidade da imagem, uma renderiza√ß√£o pode levar horas


DATA: 20/Agosto/24
## Pipeline gr√°fico
- sequ√™ncia de etapas com entrada de dados - processamento por etapas
- idealmente os processos podem ser paralelizados (como em uma pipeline padr√£o de processador)
- o gargalo (bottleneck) da pipeline √© o processo mais lento - uma pe√ßa de hardware mais fraca pode desacelerar o processo
- est√°gio de aplica√ß√£o ainda est√° contido no c√≥digo - a maioria das informa√ß√µes e bufferiza√ß√µes acontece aqui
- processamento geom√©trico monta os v√©rtices e come√ßa a gera√ß√£o de pol√≠gonos
- depois de todo o posicionamento correto na cena, entra a rasteriza√ß√£o
  - tamanho da imagem
  - resolu√ß√£o
  - posicionamento √† partir da posi√ß√£o da c√¢mera
  - aplica algoritmos espec√≠ficos para diferentes fases
  - os pr√©pixels (fragmentos) s√£o settados
  - input - v√©rtice montados
  - output - fragmentos
- pixel processing pega os fragmentos e processa
  - variando com as informa√ß√µes passadas √Ä ele, ele gera a imagem de verdade
  - d√° pra ter mais de um frag pra mesma posi√ß√£o de pixel
    - aqui ele d√° um blend e entende a cor final do pixel
- a√≠ d√° o resultado final - frame buffer 
  - d√° pra meter uns efeito em cima ainda
  - isso aqui √© o p√≥s-processamento

DATA: 27/Agosto/24
- Pixel Shader == Fragment Shader

### Shaders
Vers√µes mais atuais das ferramentas de processamento gr√°fico todas usam uma *Programmable pipeline*, existente desde do OpenGL 2.0. Processadores mais modernos todos utilizam pipelines program√°veis.
Essas pipelines program√°veis, ao inv√©s de apenas lan√ßar a *geometry data* dentro da GPU e largar na tela, ela pega os dados, lan√ßa *buffer*, *shader* e etc, e pode lan√ßar e receber dados da tela ou de outros buffers.
GLEW/GLAD s√£o bibliotecas alcan√ßadas em tempo de execu√ß√£o do c√≥digo e utilizam o padr√£o OpenGL (porque √© isso que ele √© apenas).
Temos 4 est√°gios dentro da pipeline program√°vel da OpenGL:
‚Ä¢ Est√°gio de Vertex shading
  ‚Äì Processa cada v√©rtice separadamente
  - antes de rasterizar (achatar) a geometria pra 2D
‚Ä¢ Est√°gio de Tesselation shading -> opcional
  ‚Äì Gera geometria dentro do pipeline (com c√≥digo)
‚Ä¢ Est√°gio de Geometry shading -> opcional
  ‚Äì Processa cada primitiva separadamente
‚Ä¢ Est√°gio de Fragment shading
  ‚Äì Processa cada fragmento separadamente

Pelo guia do OpenGL 4.3, a ordem do pipeline √© a seguinte: *Vertex data* => *Vertex shader* => *Tessellation / Control / Shader* => *Tessellation / Evaluation / Shader* => *Geometry / Shader* => *Rasterization* => *Clipping* => *Primitive Setup* => *Fragment Shader* => Imagem representada na tela.

Shaders, nesse sentido, s√£o simplesmente mini-programas que identificam **como** desenhar algo na tela. S√£o *especificamente* montados pra rodar na **GPU**.
Existem 3 tipos/est√°gios de Shaders:
‚Ä¢ Vertex Shaders: descrevem *como* tratar um *v√©rtice*
  ‚Äì Posi√ß√£o (3D -> 2D)
  ‚Äì Coordenadas de Textura
  ‚Äì Cor
‚Ä¢ Fragment Shaders: descrevem *como* tratar uma *√°rea* (pixel-size)
  ‚Äì Cor
  ‚Äì Z-depth
  ‚Äì Alpha value
  - processamento de pixeis
  - em alguns momentos os fragmentos de sobrep√µe e ocupam o mesmo pixel (normalmente ficam ocultos)
  - *Depth testing* evita redu√™ncia de fragmentos no mesmo pixel
  - todas as cores s√£o em RGBA normalizadas
  - aqui existem alguns comandos √∫teis para usar
    - points (s√≥ os pontos)
    - lines (v√©rtices)
    - line_strip (conecta linhas desconectadas)
    - line_loop (cria√ß√£o de tri√¢ngulo)
    - triangles (gerar mais de um tri√¢ngulo na tela)
    - triangle_strip (preencher espa√ßos entre os tri√¢ngulo - agrupar)
    - triangle_fan (faz um catavento de tri√¢ngulos)
‚Ä¢ Processados paralelamente
  ‚Äì Um para cada v√©rtice de um modelo
  ‚Äì Um para cada fragmento

A pipeline toda vai rodar em paralelo usando diversos n√∫cleos de processadores da GPU. O paralelismo nesse caso √© real. Nesse sentido, d√° pra escolher um shader que tenha nosso objetivo e fa√ßa uma diferen√ßa bastante clara no resultado final do resultado do processamento. Anima√ß√£o e diferencia√ß√£o do objeto acontecem nessa √°rea - todos esses processos na GPU s√£o *pipeline do hardware*.
O paralelismo da execu√ß√£o dos shaders √© montado especificamente pra execu√ß√£o em telas e rodagem em GPU's (ou melhor, GPU's foram montadas para processamento matricial, necess√°rio em computa√ß√£o gr√°fica). Essa execu√ß√£o, principalmente de shaders, necessita de *shader cores*; se uma imagem necessita de 200 deles, 200 ser√£o usados ao mesmo tempo.
Os shader cores processam um n√∫mero fixo de primitivas por vez pelo *buffer VAO* - j√° que eles os fazem, por isso √© interessante manter o n√∫mero de malhas usadas *baixo* - j√° que todas essas execu√ß√µes s√£o feitas em paralelo.
  As primitivas desse buffer s√£o chamadas pelas *drawcalls* - quanto mais delas, mais malhas e mais buffers - podendo sobrecarregar a GPU.
Tenha aten√ß√£o para a programa√ß√£o dos shaders, j√° que eles dependem da vers√£o utilizada do OpenGL. Dito isso, ele vai com certeza ter alguns tipos diferentes para realizar as chamadas.
Sempre separe os shaders em arquivos de texto separados - como uma boa pr√°tica
- programas (pequenos) que implementam/definem/processam info para serem desenhados (geometrias/fragmentos) para o desenho (render) junto com a API gr√°fica
  - s√£o compilados especificamente pra rodar na placa gr√°fica (GPU)
- Shading != shaders (pero no mucho)
  - shading (fazer o sombreamento na solid view) utiliza shaders pra conseguir rodar, mas o *shading* serve como um processo maior conceitualmente
- o compilador do c√≥digo de shader √© a pr√≥pria API gr√°fica do OpenGL (GLSL) - nessa caso, se estiver utilizando outra biblioteca gr√°fica ela vai dar conta do recado √† sua maneira
  - GLSL √© uma linguagem de Shader

### Buffer
A defini√ß√£o mais b√°sica de *buffer* √© que ele √© uma unidade de mem√≥ria separada para guardar informa√ß√µes. Esses dados s√£o colocados em um dispositivo de sa√≠da, um *frame buffer*.

DATA: 10/Setembro/2024
# Sistema de coordenadas
‚Ä¢ Coordenadas locais (local space)
‚Ä¢ Coodenadas de Universo (world space) ‚Äì Sistema de Refer√™ncia do Universo
(SRU)
‚Ä¢ Coordenadas de camera (view space)
‚Ä¢ Espa√ßo de Recorte (clip space)
‚Ä¢ Coordenadas de Tela (screen space) ‚Äì Sistema de Refer√™ncia de Tela (SRT)

A diferen√ßa mais b√°sica entre uma **window** e uma **viewport** √© que a *window* determina a por√ß√£o/√°rea da cena que ser√° mostrada; enquanto que a *viewport* determina a *forma* dessa por√ß√£o - al√©m de montar a escala e o mapeamento de rederiza√ß√£o.

- Sistemas de proje√ß√µes e de janelas
- sempre exite o c√°lculo da transposi√ß√£o da c√¢mera para o recalculo
- no momento q largar o objeto define a posi√ß√£o dele em rela√ß√£o ao sistema de coordenadas
- as coordenadas "originais" s√£o de -1 a 1 (pelo menos no OpenGL) e se n√£o ouver defini√ß√£o do objeto no espa√ßo ele vai estar dentro desse espa√ßo
- o primeiro mapeamento entre o *world space* ou o espa√ßo de mundo/universo. -> relacionado √° c√¢mera, claro (que tamb√©m √© um objeto)
- no Blender, por exemplo, se coloca a c√¢mera na cena para ter uma no√ß√£o de composi√ß√£o de cena
  - colocar no ponto de vista
  - *view point* -> ponto de vista da c√¢mera (de render)
  - as ferramentas de processamento gr√°fico (Blender, Unity, etc) todas permitem altera√ß√µes das configura√ß√µes base das pipelines gr√°ficas
  - d√° pra mexer sem medo, as ferramentas s√≥ d√£o uma facilitada
- o objeto central come√ßa na origem do plano cartesiano (origem do mundo)
- ainda precisa definir duas matrizes (transforma√ß√µes) - rota√ß√µes, transla√ßoes e escalas
- a matriz passa para o *view space* e a matriz de proje√ß√£o passa para o *clip space* para a√≠ escalar no *screen space*
  - Tudo √© montado no processo de *vertex shader*
- a aplica√ß√£o pode ter mais de uma viewport
  - elas podem ter vis√µes completamente diferentes
- *viewpoint* se refere a tela
  - por√ß√µes que ser√£o exibidas pelo CG
- *Window* √© um resultado das opera√ß√µes de view e projection - ainda n√£o foi normalizado para os pixeis
  - podem existir viewports diferentes para a mesma window
- *aspect ratio* - raz√£o de aspecto - defini√ß√£o de largura e altura
  - valor 1 entrega um quadrado - valores maiores que um mostram cenas achatadas e menores alongadas
- a proje√ß√£o √© montada do pbservador at√© o plano de proje√ß√£o
  - se a dist√¢ncia do observador for infinita a proje√ß√£o √© paralela
  - caso n√£o sempre vai ter alguma *perspectiva*
    - proje√ß√£o perpendicular

## Proje√ß√µes
As proje√ß√µes planares paralelas e perspectivas diferem com rela√ß√£o a dist√¢ncia do plano de proje√ß√£o ao centro de proje√ß√£o:
‚Äì se a dist√¢ncia √© finita, a proje√ß√£o √© **perspectiva**, e
‚Äì se a dist√¢ncia √© infinita, a proje√ß√£o √© **paralela**
  ‚Ä¢ Proje√ß√£o ortogonal (ou ortogr√°fica): as linhas
  projetadas s√£o perpendiculares ao plano da
  proje√ß√£o.
  ‚Äì Isso mant√©m a escala uniforme em todas as
  dire√ß√µes.
  ‚Ä¢ Proje√ß√£o obl√≠qua: As linhas projetadas podem
  estar em um √¢ngulo, mas ainda permanecem
  paralelas.

-> tenha em mente que *perspectivas* demonstram pontos de fuga

- c√¥nicas
  - todos os pontos de fuga se re√∫nem
  - mais naturalidade √† cena
  - objetos aumentam conforme proximidade do observador
- paralelas
  - exclui a caracter√≠stica de dist√¢ncia
  - perserva tamanhos e proje√ß√µes dos objetos
  - desconsidera o observador
  - pode ser √∫til na composi√ß√£o de cena (evita enganos de perspectiva)
  - gera perda de informa√ß√£o de profundidade
- a modelagem gera as imagens com multiplica√ß√µes de matrizes (facilita pra GPU)
  - 4x4 - mat4 -> opera√ß√µes matriciais de 4x4 facilitam pela representa√ß√£o das coordenadas
  - uma das bibliotecas mais simples √© GLM - s√≥ os cabe√ßalhos pra colocar no OpenGL  

## GLM
Essa √© a biblioteca para trabalhar com matem√°tica dentro do OpenGL

## Matriz de view
Define a matriz do viewport - posicionamento da C√¢mera
Isso aqui vai multiplicar duas matrizes com os vetores de posicionamento e vai formar a orienta√ß√£o da c√¢mera

## Proje√ß√£o ortogr√°fica
‚Äì *ùëô* (left): coordenada da borda esquerda do plano de corte.
‚Äì *ùëü* (right): coordenada da borda direita do plano de corte.
‚Äì *ùëè* (bottom): coordenada da borda inferior do plano de corte.
‚Äì t (top): coordenada da borda superior do plano de corte.
‚Äì n (near): dist√¢ncia ao plano de corte mais pr√≥ximo (em Z).
‚Äì f (far): dist√¢ncia ao plano de corte mais distante (em Z)
‚Äì ùëü ‚àí ùëô e ùë° ‚àí ùëè: controlam a escala horizontal e vertical do volume de visualiza√ß√£o.
‚Äì ùëì ‚àí ùëõ: controla a escala no eixo Z
‚Äì ‚àí ùëú+ùëô
ùëú‚àíùëô e ‚àí ùëú+ùëè
ùëú‚àíùëè : deslocam a posi√ß√£o da c√¢mera, permitindo que o centro do volume
de visualiza√ß√£o n√£o esteja na origem

Essa ortogonalidade vai modificar toda a representa√ß√£o ortogr√°fica da cena e alterar o tamanho e composi√ß√£o de cena.

## Scrolling
Aqui a c√¢mera √© settada para seguir o personagem e as dimens√µes de mundo s√£o maiores que a viewport.
Logicamente precisa setar um objeto como o personagem e lockar a c√¢mera nele
Em 2D e uma c√¢mera sem perspectiva


DATA:17/Setembro/24
# Transforma√ß√µes
Todas as transforma√ß√µes e rota√ß√µes utilizam matrizes para os c√°lculos.
Al√©m disso, precisam ainda transferir o objeto para a origem e depois ainda colocar na posi√ß√£o necess√°ria.

‚ñ™ vec2: ponto 2D (x,y) ou coordenada de textura (s,t)
‚ñ™ vec3: ponto ou dire√ß√£o 3D (x,y,z)
‚ñ™ vec4: ponto 4D (x,y,z,1.0) ou dire√ß√£o 4D (x,y,z,0.0)
‚ñ™ Lembre-se que uma matriz 4x4 s√≥ pode ser transformada
por um vetor 4D e uma matriz 3x3 por um vetor 3D

- nos objetos
- precisar usar trigonometria pra fazer os giros (claramente j√° que √© o espa√ßo)

Uma vez que a trigonometria √© bastante utilizada, sinta-se encorajado para dar uma olhada neste projeto iterativo sobre o mesmo: https://phet.colorado.edu/en/simulations/trig-tour -> prometo que o site √© seguro

Outro recurso muit√≠ssimo utilizado s√£o as matrizes, uma vez que as imagens se d√£o em uma matriz (a tela do computador), nada mais justo que os c√°lculos serem matriciais.
Todas as opera√ß√µes com matrizes s√£o utilizadas aqui, sinta-se a vontade para revisar opera√ß√µes com matrizes em https://pt.khanacademy.org/math/algebra-home/alg-matrices

Tenha em mente que as transforma√ß√µes ocorrem por meio dos c√°lculos angulares trigonom√©tricos e matriciais, mas n√£o se preocupe, o OpenGL (e outras bibliotecas gr√°ficas) o fazem por voc√™ (o trabalho pesado pelo menos).

## Transla√ß√£o
√â a movimenta√ß√£o de um objeto pelos eixos - todos os pontos do pol√≠gono s√£o movidos
xt = x + Tx
yt = y + Ty

## Escala
Altera-se o "tamanho" do objeto, ou a sua escala. Pontos podem ficar maiores, arestas aumentam de tamanho, a √°rea/volume do pol√≠gono se altera, etc
Existem escalas uniformes e n√£o uniformes, conforme Ex = Ey e Ex != Ey
Para realizar esse c√°lculo multiplica-se um fator de escala:
xe = x * Ex
ye = y * Ey

## Rota√ß√£o
A rota√ß√£o √© interessante uma vez que ela necessita trazer o objeto novamente para a origem, rotacion√°-lo e a√≠ sim devolv√™-lo para a regi√£o de onde foi retirado - isso porqu√™, caso contr√°rio, ele mudaria de posi√ß√£o ao inv√©s de √¢ngulo (j√° que √© uma soma simples e as posi√ß√µes dos pontos tamb√©m mudam).
√â basicamente uma soma de √£ngulos, de forma que os pontos formam um √¢ngulo Œ± em rela√ß√£o √† origem. Quando aplicamos uma rota√ß√£o, adicionamos um √¢ngulo Œ∏ √† Œ±, e com isso precisamos recalcular a posi√ß√£o dos pontos conforme esse novo √¢ngulo Œ±+Œ∏
xr = x.cos(Œ∏) - y.sen(Œ∏)
yr = y.cos(Œ∏) + x.sen(Œ∏)

Para evitar movimenta√ß√µes desnecess√°rias no plano:
x' = (x - xp).cos(Œ∏) ‚Äì (y ‚Äì yp).sin(Œ∏) + xp
y' = (x - xp).sin(Œ∏) + (y ‚Äì yp).cos(Œ∏) + yp
-> esse √© o chamado pivot da rota√ß√£o.

## Outras transforma√ß√µes
Ainda existem algumas outras mais situacionais, como:

### Reflex√£o
Eixo X
x‚Äô = x
y‚Äô = -y

Origem
x‚Äô = -x
y‚Äô = -y

Eixo Y
x‚Äô = -x
y‚Äô = y

### Shearing (deslizamento)
xs = x + Sx
ys = y + Sy

Isso √© uma manipula√ß√£o de um dos lados de um pol√≠gono

## Homogeneiza√ß√£o de matrizes e vetores
Isso vale tanto para objetos 2D quanto 3D.
Se rezume a completar o vetor um um 3¬∞ elemento para homogeneiz√°-lo. J√° que os c√°lculos matriciais e vetoriais necessitam de opera√ß√µes *completas*, ou seja, uma matriz precisa *necessariamente* ser quadr√°tica, essa homogeiniza√ß√£o adiciona o valor **1** para completar.
Esse multiplica√ß√£o e usabilidade √© poss√≠vel a partir do momento que o OpenGL ainda guarda as informa√ß√µes de matrizes vetorizadas e precisa calcular para matrici√°-las e jog√°-las na placa de v√≠deo.

DATA 24/Setembro - 1¬∞/Outubro/2024
# Texturas
As texturas surgiram para fazer uma "imita√ß√£o" do que seria tal elemento com todos os pol√≠gonos presentes. Subtitui a necessidade de utilizar diversos pol√≠gonos enquanto ainda causa a ilus√£o de uma superf√≠cie.
Tudo que precisamos fazer √© informar ao OpenGL os "cantos" do pol√≠gono, ou melhor, a regi√£o que tal textura precisa ficar que o **fragment shader** cuida da **interpola√ß√£o** (preenche o resto).
Utilizando como coordenadas b√°sicas de 0 a 1, um poss√≠vel c√≥digo para "placement" de uma textura poderia ser:

```C++
GLfloat texCoords[] = {
0.0f, 0.0f, // Inferior esquerdo
1.0f, 0.0f, // Inferior direito
1.0f, 1.0f, // Superior direito
0.0f, 1,0f // Superior esquerdo
};
```
## Texture Wrapping
Entre os pontos, o OpenGL pode fazer algumas coisas:
‚Äì GL_REPEAT: comportamento padr√£o, que repete a imagem de textura
‚Äì GL_MIRRORED_REPEAT: mesmo que GL_REPEAT mas espelha a imagem a cada repeti√ß√£o.
‚Äì GL_CLAMP_TO_EDGE: ‚Äúprende‚Äùas coordenadas entre 0 e 1. Os valores mais altos ficam presos √†s arestas.
‚Äì GL_CLAMP_TO_BORDER: coordenadas for a do intervado recebem uma cor de borda.

Existem algumas maneiras de settar, mas as coordenadas s e t s√£o necess√°rias; trate como x e y:
```C++
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
```

## Texture Filtering
Ou **Texture smoothing**. Esse processo serve para consertar problemas causados por compress√£o ou aumento muito grande de imagem (as texturas). Algumas t√©cnicas podem ser usadas:

### Neares Neighbor Filtering
Se falta pixel pega a cor do vizinho mais pr√≥ximo
```C++
glTexParameter(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameter(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
```
A imagem tem tend√™ncia de ficar pixelada e bastante forte.

### Linear Filtering
Faz uma m√©dia de todos os vizinhos; os pixels faltantes tem uma cor mediana.
Normalmente geram imagens mais *fuzzy* ou pouco n√≠tidas.
```C++
glTexParameter(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
glTexParameter(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
```

## Minimaps
O OpenGL pode gerar imagens menores de uma textura automaticamente.
A biblioteca faz divis√µes lineares (divis√µes por 2) diversas vezes e armazena vers√µes *miniaturizadas* das mesmas imagens.
Existe um m√©todo padr√£o, mas √© poss√≠vel especific√°-lo com:
‚Äì GL_NEAREST_MIPMAP_NEAREST: usa o mipmap mais pr√≥ximo do tamanho do pixel e usa o m√©todo de interpola√ß√£o do vizinho mais pr√≥ximo para amostrar a textura
‚Äì GL_LINEAR_MIPMAP_NEAREST: usa o mipmap mais pr√≥ximo do tamanho do pixel e usa o m√©todo de interpola√ß√£o linear para amostrar a textura
‚Äì GL_NEAREST_MIPMAP_LINEAR: faz a interpola√ß√£o linear dos dois mipmaps mais pr√≥ximos ao tamanho do pixel e usa o m√©todo de interpola√ß√£o do vizinho mais pr√≥ximo para amostrar a textura
‚Äì GL_LINEAR_MIPMAP_LINEAR: faz a interpola√ß√£o linear dos dois mipmaps mais pr√≥ximos ao tamanho do pixel e usa o m√©todo de interpola√ß√£o linear para amostrar a textura
 
```C++
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
```

## Mapeamento UV em modelos 3D
√â um mapeamento do objeto 3D. Como se fosse uma planta baixa mesmo. Igual quando mont√°vamos bonecos de papel os quais formavam cubos.
Tem algumas etapas, mas a principal delas √© o **mapeamento de textura**. A mesma planta baixa, mas com as texturas aplicadas. √â consideravelmente mais simples aplicar texturas em pol√≠gos simples que em poliedros.

## Inicializa√ß√£o de texturas
As texturas precisam ser obviamente inicializadas e colocadas dentro do projeto na hora do carregamento.
Cheque abaixo alguns dos m√©todos para inicializ√°-las.

- **Gere o ID da textura**
```C++
// Gera o identificador da textura na mem√≥ria
glGenTextures(1, &texID);
glBindTexture(GL_TEXTURE_2D, texID);
```

- **Ajuste os par√¢metros de *wrapping* e *filtering***
```C++
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);

glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
```

- **Fa√ßa o carregamento da imagem**
-> Com a biblioteca stb_image (https://github.com/nothings/stb), esse processo √© mais facilitado; considere dar um check.
```C++
int width, height, nrChannels;

unsigned char *data = stbi_load(filename.c_str(), &width, &height,
&nrChannels, 0);
```

- **Agora √© s√≥ mandar os dados para a mem√≥ria do OpenGL e trabalho feito**
```C++
if (data)
{
  if (nrChannels == 3) //jpg, bmp
  {
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
  }
  else //png
  {
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, data);
  }
  glGenerateMipmap(GL_TEXTURE_2D);
  }
else
{
  std::cout << "Failed to load texture" << std::endl;
}
```

- **Algumas boas pr√°ticas interessantes**
```C++
// Considere sempre liberar o buffer de mem√≥ria depois de usar (isso aqui ainda √© baseado em C, ou seja, n√£o existem muitas ferramentas de unassign de mem√≥ria)
stbi_image_free(data);

glBindTexture(GL_TEXTURE_2D, 0);

// Precisa ativar o buffer de textura do OpenGL
glActiveTexture(GL_TEXTURE0);

// Sempre fa√ßa o bind das unidades de textura (as imagens mesmo) com os buffers os quais elas precisam estar relacionadas
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, textID1);
glActiveTexture(GL_TEXTURE1);
glBindTexture(GL_TEXTURE_2D, textID2);
glBindVertexArray(VAO);
glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
```

## Buffers
Agora os buffers do OpenGL possuem mais atributos e nossos leitores precisam espelhar tal fato.
Considere montar estruturas parecidas:
```C++
float vertices[] = {
// posicoes // cores // coordenadas de textura
0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0, // superior direito
0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, // inferior direito
-0.5f, -0.5f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, // inferior esquerdo
-0.5f, 0.5f, 0.0f, 1.0f, 1.0f, 0.0f, 0.0f, 1.0 // superior esquerdo
};
unsigned int indices[] = {
0, 1, 3, // primeiro triangulo
1, 2, 3 // segundo triangulo
};

//-------------------------------------------------------------------------
glGenVertexArrays(1, &VAO); glGenBuffers(1, &VBO); glGenBuffers(1, &EBO);
glBindVertexArray(VAO);
glBindBuffer(GL_ARRAY_BUFFER, VBO);
glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);
glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);
// position attribute
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);
glEnableVertexAttribArray(0);
// color attribute
glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(3 * sizeof(float)));
glEnableVertexAttribArray(1);
// texture coord attribute
glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));
glEnableVertexAttribArray(2);
```

**N√£o esque√ßa do vertex shader!**
```C++
#version 450 core
layout (location = 0) in vec3 position;
layout (location = 1) in vec3 color;
layout (location = 2) in vec2 tex_coord;
out vec4 vertexColor;
out vec2 texCoord;
uniform mat4 model;
uniform mat4 projection;
void main()
{
gl_Position = projection * model * vec4(position, 1.0f);
vertexColor = vec4(color,1.0);
texCoord = vec2(tex_coord.x, tex_coord.y);
}

//---------------------------------------------------------
#version 450 core
in vec3 vertexColor;
in vec2 texCoord;
out vec4 color;
// pixels da textura
uniform sampler2D tex_buffer;
void main()
{
color = texture(tex_buffer, texCoord);
}
```

## Finalizando
Alguns lembretes na hora de finalizar seus m√©todos para completar o programa:
```C++
//N√£o esquecer de chamar o m√©todo para carregar a imagem ‚ò∫
GLuint texID = loadTexture("./textures/mario.png");

// N√£o esquecer de especificar a vari√°vel uniform que vai conter os dados da textura no fragment shader
glUniform1i(glGetUniformLocation(shader.ID, "tex_buffer"), 0);

//Antes da drawcall:
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, texID);
glBindVertexArray(VAO);
glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
glBindVertexArray(0);
```

# Camads de sprites e cen√°rios 2D
Cada ciclo do *Game Loop* vai gerar um sprite diferente. Lembre-se de que o game loop sempre passa pelo renderer um update e um sync.
Os sprites est√£o presentes dentro de uma **Spritesheet**, como uma contendo os est√°gios de anima√ß√£o de um personagem.
Tal personagem pode possuir uma SpriteSheet com o loop de caminhada que se repete toda vez que ele caminha, dessa forma, o game loop tamb√©m "caminha" pela spritesheet mostrando as fases.
O posicionamento das imagens √© baseado em x, y e z.
Para que o sprite exista, ele precisa estar associado a um quadril√°tero qualquer, para que o sprite sirva como uma "textura".
Todas as imagens vem pelo *shader*. Veja uma implementa√ß√£o simples:
```C++
glEnable(GL_DEPTH_TEST);
glDepthFunc(GL_ALWAYS);

glClear(GL_COLOR_BUFFER_BIT |
GL_DEPTH_BUFFER_BIT);

// Para existir transpar√™ncia, use:
glEnable(GL_BLEND);
glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);
```
## Recorte de imagens - Spritesheet
A spritesheet funciona basicamente como uma matriz mesmo.
Divide-se o "papel" onde ela est√° em diferentes segmentos os quais correspondem a est√°gios da anima√ß√£o. Assim sendo, tudo que o programa faz √© navegar pelos diferentes est√°gios dessa matriz que √© a spritesheet.
Uma implementa√ß√£o de uma spritesheet deve levar em conta, agora, os frames de anima√ß√£o presentes. Para isso, uma implementa√ß√£o necess√°ria √©:
```C++
iFrame = (iFrame+1) % nFrames
```

Os **Offsets** ser√£o basicamente coordenadas para puxar determinado sprite.
Tenha como exemplo:
```C++
// Na inicializa√ß√£o do sprite
dx = 1.0 / (float)nFrames;
dy = 1.0 / (float)nAnimations;
float vertices[] = {
// positions // colors // texture coords
0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, dx, dy, // top right
0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, dx, 0.0f, // bottom right
-0.5f, -0.5f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, // bottom left
-0.5f, 0.5f, 0.0f, 1.0f, 1.0f, 0.0f, 0.0f, dy // top left
};

// Na atualiza√ß√£o do sprite
GLint offsetLoc = glGetUniformLocation(shader->Program, "offset");
glUniform2f(offsetLoc, iFrame * dx, iAnimation * dy);
iFrame = (iFrame + 1) % nFrames;

// No shader
#version 450 core
in vec2 TexCoord;
out vec4 color;
// pixels da textura
uniform sampler2D tex1;
//Texture coords offsets for animation
uniform vec2 offset;
void main()
{
color = texture(tex1, TexCoord+offset);
}

// Dentro do gameloop, ainda √© necess√°rio implementar algum tipo de timer para coordenar os sprites
//GAME LOOP
while (!glfwWindowShouldClose(window))
{
timer.start();
//faz as chamadas de update e desenho...

// E ainda uma classe timer
#include <chrono>
#include <thread>
#include <ctime>
class Timer
{
public:
Timer();
void start() { begin = std::chrono::system_clock::now(); }
void finish() { end = std::chrono::system_clock::now(); }
double getElapsedTimeMs()
{
std::chrono::duration<double> elapsed_seconds = end - begin;
return elapsed_seconds.count() * 1000;
}
double getElapsedTime()
{
std::chrono::duration<double> elapsed_seconds = end - begin;
return elapsed_seconds.count();
}
double calcWaitingTime(int fps, double elapsedTime) {
double wt = 1000 / (double)fps - elapsedTime;
return wt;
}
protected:
// Using time point and system_clock
std::chrono::time_point<std::chrono::system_clock> begin,
end;
};
```

Ainda √© necess√°rio implementar um **waiting time**. Caso ele n√£o exista, a anima√ß√£o funciona, mas ela fica descompassada e n√£o-natural.
√â bastante interessante usar um waiting time a fim de, por exemplo, colocar uma velocidade diferente do personagem correndo e andando (de anima√ß√£o no caso).
```C++
double calcWaitingTime(int fps, double elapsedTime) {
  double wt = 1000 / (double)fps - elapsedTime;
  return wt;
}

//GAME LOOP
while (!glfwWindowShouldClose(window))
{
  timer.start();
  glfwPollEvents();
  //...Chama m√©todos de atualiza√ß√£o e desenho dos objetos da cena....
  //Sincronizando o FPS
  timer.finish();
  double waitingTime = timer.calcWaitingTime(60, timer.getElapsedTimeMs());
  if (waitingTime)
  {
  std::this_thread::sleep_for(std::chrono::milliseconds((int)waitingTime));
  }
  glfwSwapBuffers(window);
}
```

## Camadas e Parallax
O efeito de parallaxe n√£o √© exatamente simples de ser executado.
Na realidade, √© necess√°rio quebrar quebrar a imagem em algumas camadas (como √°rvores mais adentro separado de uma casa ao fundo) para ser poss√≠vel *simular* a realidade.
Como na inven√ß√£o de anima√ß√£o do Walt Disney (d√™ uma olhada https://www.youtube.com/watch?v=YdHTlUGN1zw), as camadas se movem e tem comportamento um tanto diferentes. A magia est√° no movimento.
Essa implementa√ß√£o de camadas s√£o os **layers**
A viewport sendo uma c√¢mera, se comporta tal qual a inven√ß√£o e um offset √© necess√°rio:
```C++
layers[i]->setOffsets(offsetx,offsety);
```
Considerando que ainda s√£o "texturas", precisamos definir coordenadas x e y, assim como defini√ß√£o de qual layer √©.

Uma forma de implementa√ß√£o seria:
```C++
for all layers [0..n]
layers[i]->computeScrollRateX(mainLayer->getWidth());
layers[i]->computeScrollRateY(mainLayer->getHeight());

for all layers [0..n]
layers[i]->scroll(forward);

for all layers [0..n]
layers[i]->plot(viewport); // ser√° alterado para anima√ß√£o

for all layers [0..n]
layers[i]->computeScrollRateX(mainLayer->getWidth());
layers[i]->computeScrollRateY(mainLayer->getHeight());

for all layers [0..n]
layers[i]->scroll(forward);
```

DATA: 15/Outubro/2024
# Gera√ß√£o de colis√£o
Uma implementa√ß√£o de colis√£o simples √© considerar os lados dos pol√≠gonos e identificar se eles est√£o sobrepostos.
Veja a implementa√ß√£o simples:
```C++
bool checkCollision(Sprite &one, Sprite &two)
{
  // collision x-axis?
  bool collisionX = one.getPMax().x >=
  two.getPMin().x &&
  two.getPMax().x >= one.getPMin().x;
  // collision y-axis?
  bool collisionY = one.getPMax().y >=
  two.getPMin().y &&
  two.getPMax().y >= one.getPMin().y;
  // collision only if on both axes
  return collisionX && collisionY;
}
```

DATA: 22/Outubro - 12/Novembro/2024
# Sistemas de cores e Introdu√ß√£o ao Processamento de Imagens
Processamento gr√°fico trabalha com imagens puras e o processamento de imagens ainda segue as normas previamente vistas.
Grosso modo  uma *imagem* √©, "nas ci√™ncias exatas, como a matem√°tica, o termo "imagem" √© entendido como representa√ß√£o de um objeto especializado, que exige t√©cnicas e ferramentas especiais." - wikip√©dia
Como trabalhamos com matrizes de valores, uma imagem √© isso mesmo, uma matriz de **pixels** - *picture elements*.
Cor, sendo uma percep√ß√£o visual de luz e a luz, sendo uma onda/part√≠cula, telas podem transmitir perfeitamente ilus√µes de luz.
Se quiser mais informa√ß√µes sobre cores, luz e etc., acesse https://pt.wikipedia.org/wiki/Cor

Existe o Diagrama de Cromaticidade CIE que √© basicamente uma forma (X+Y+Z)=1 planificada em x e y, nesse caso, √© uma forma meio bizarra onde as cores puras est√£o nas pontas.

A gera√ß√£o de imagens pelo computador depende de hardware, o qual pode ser por:
CRT (Cathode Ray Tube) - m√©todo de TV's de tubo
LCD (Liquid Cristal Display) - tem v√°rios componentes de luz ligados em uma central - v√°rios feixed de luz.

As dimens√µes da tela ainda usam os dimensionamentos padr√£o (640x480, 1280x1024) - o produto dessas dimens√µes identifica os **megapixels** - produto de largura pela altura

A quantidade de bits pode alterar a quantidade de cores representadas na tela. Por isso usualmente imagens e processamentos em gray scale s√£o mais leves
O b√°sico √© que o *truecolor* surge a partir de 24 bits e √© a√≠ que o canal alfa (luminosidade) aparece para uso.
Caso queira mais informa√ß√µes sobre luminosidade, acesse https://pt.wikipedia.org/wiki/Profundidade_de_cor

Dessa forma, uma imagem √© basicamente um conjuto de pixels, cada um com uma coordenada espec√≠fica

Os modelos mais comuns de uso de cores s√£o o RGB, CMY(K), HSV.
Cheque mais detalhes em https://pt.wikipedia.org/wiki/RGB, https://pt.wikipedia.org/wiki/CMYK e https://pt.wikipedia.org/wiki/HSV.
Inclusive, HSV √© um dos modelos mais utilizados para editores de imagem.

### Refer√™ncias
- Real-time rendering - 4th ed. / 2018 - ( Livro eletr√¥nico ) 
  - https://pdfroom.com/books/real-time-rendering/XDkgVjmNg9B -> aparentemente o leitor de PDF funciona
 wow
- LearnOpenGL - Anton's OpenGL 4 Tutorials
- Slides sobre CG dos professores: Christian Hofsetz, Cristiano Franco, Marcelo Walter, Soraia Musse, Leandro Tonietto e Rafael Hocevar
- Cohen, M., & Manssour, I. H. (2006). OpenGL: uma abordagem pr√°tica e objetiva. Novatec editora
- Notas de Aula do professor Leandro Tonietto
- Notas de aula do professor Marcelo Walter (UFRGS)
- Notas de aula do professor Bruno Carvalho (UFRN)
- FOLEY, J.D. et al. Computer graphics: principles and practice. Reading: Addison-Wesley, 1990.
- TONIETTO, Leandro; WALTER, Marcelo. An√°lise de Algoritmos para Chroma-key. Unisinos, 2000.
- https://learnopengl.com//#!Getting-started/Transformations
- https://learnopengl.com/Getting-started/Textures
- https://learnopengl.com/